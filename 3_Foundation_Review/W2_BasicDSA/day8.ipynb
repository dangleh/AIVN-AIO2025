{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng 2 vector: (2, 3, 3, 6)\n",
      "Tích 2 vector: (6, 18)\n",
      "Khoảng cách giữa hai vector: 3.1622776601683795\n",
      "Vị trí của số 3 trong vector 1: 1\n",
      "Vị trí của số 3 trong vector 2: 0\n"
     ]
    }
   ],
   "source": [
    "# Day 8: Tuple and List\n",
    "# 1, 2\n",
    "my_tuple1 = (2,3)\n",
    "my_tuple2 = (3,6)\n",
    "\n",
    "print(f\"Tổng 2 vector: {my_tuple1 + my_tuple2}\")\n",
    "\n",
    "result = []\n",
    "for i in range(len(my_tuple1)):\n",
    "  result.append(my_tuple1[i] * my_tuple2[i])\n",
    "print(f\"Tích 2 vector: {tuple(result)}\")\n",
    "\n",
    "# 3\n",
    "import math\n",
    "distance_squared = (my_tuple1[0] - my_tuple2[0])**2 + (my_tuple1[1] - my_tuple2[1])**2\n",
    "distance = math.sqrt(distance_squared)\n",
    "print(f\"Khoảng cách giữa hai vector: {distance}\")\n",
    "\n",
    "# 4\n",
    "index_tuple_1 = my_tuple1.index(3)\n",
    "index_tuple_2 = my_tuple2.index(3)\n",
    "print(f\"Vị trí của số 3 trong vector 1: {index_tuple_1}\")\n",
    "print(f\"Vị trí của số 3 trong vector 2: {index_tuple_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag-of-Words: ['AI', 'Toán', 'Tôi', 'môn', 'nhạc', 'thích', 'âm']\n",
      "Tôi thích AI thích Toán: [1, 1, 1, 0, 0, 2, 0]\n"
     ]
    }
   ],
   "source": [
    "# Day 8: Bag of Word (BoW) - NLP\n",
    "# Vocabulary\n",
    "# corpus\n",
    "# vector\n",
    "corpus = [\"Tôi thích môn Toán\", \"Tôi thích AI\", \"Tôi thích âm nhạc\"]\n",
    "vector = []\n",
    "\n",
    "# Cách thức thực hiện như sau:\n",
    "# – Bước 1: Chia nhỏ văn bản thành các từ riêng lẻ (không trùng nhau)\n",
    "# – Bước 2:Tạo một tập hợp các từ xuất hiện trong văn bản. Tập hợp này không\n",
    "# có phần tử trùng nhau.\n",
    "# – Bước 3: Biểu diễn văn bản input ở dạng vector: Mỗi câu (mỗi input) được\n",
    "# biểu diễn bằng một vector, với mỗi phần tử trong vector thể hiện số lần xuất\n",
    "# hiện của từ đó trong input.\n",
    "\n",
    "# Bước 1 & 2\n",
    "def create_vocabulary(corpus):\n",
    "  vocabulary = []\n",
    "  for sentence in corpus:\n",
    "    for word in sentence.split():\n",
    "      if word not in vocabulary:\n",
    "        vocabulary.append(word)\n",
    "  return vocabulary # list vocabulary\n",
    "\n",
    "vocabulary = create_vocabulary(corpus)\n",
    "vocabulary.sort() # Python sort các kí tự theo Unicode\n",
    "print(\"Bag-of-Words:\", vocabulary) # Output: Bag-of-Words: [AI, Toán, Tôi, môn, nhạc, thích, âm]\n",
    "\n",
    "# Bước 3: Biểu diễn văn bản ở dạng vector (Tokenization)\n",
    "def create_vectors(sentence, vocabulary):\n",
    "    vector = [0] * len(vocabulary) # Vector phải bằng length của vocabulary\n",
    "    for word in sentence.split():\n",
    "        if word in vocabulary:\n",
    "            index = vocabulary.index(word) # tìm index của word của sentence so với vocab \n",
    "            vector[index] += 1             # nếu có thì đánh dấu index của vector = số lần xuất hiện của word (đếm tăng dần)\n",
    "    return vector\n",
    "\n",
    "new_sentence = \"Tôi thích AI thích Toán\"\n",
    "vector_new_sentence = create_vectors(new_sentence, vocabulary)\n",
    "print(f\"{new_sentence}: {vector_new_sentence}\")\n",
    "# Output: Tôi thích AI thích Toán: [1, 1, 1, 0, 0, 2, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[2, 4, 6]\n"
     ]
    }
   ],
   "source": [
    "# Day 8: Algorithms on List\n",
    "list_data = [1, 1.1, None, 1.4, None, 1.5, None, 2.0]\n",
    "\n",
    "# Find position of first 'None' element\n",
    "for i in list_data:\n",
    "  if i == None:\n",
    "    print(list_data.index(i))\n",
    "    break\n",
    "\n",
    "# Find positions are 'None'\n",
    "result = []\n",
    "for i, element in enumerate(list_data):\n",
    "  if element == None:\n",
    "    result.append(i)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1.1, 1.1, 1.4, 1.4, 1.5, 1.5, 2.0]\n"
     ]
    }
   ],
   "source": [
    "# Day 8: Interpolation on List (Time-series)\n",
    "# Nearest Neighbor - Muc đích: Filling missing data\n",
    "list_data = [1, 1.1, None, 1.4, None, 1.5, None, 2.0]\n",
    "# Expected [1, 1.1, 1.1, 1.4, 1.4, 1.5, 2.0, 2.0]\n",
    "\n",
    "\n",
    "def nearest_neighbor_interpolate(data):\n",
    "  filled_data = []\n",
    "  for i, value in enumerate(data):\n",
    "    if value is None:\n",
    "      if i > 0 and data[i-1] is not None:\n",
    "        filled_data.append(data[i-1]) # Using previous value\n",
    "      elif i < len(data) - 1 and data[i+1] is not None:\n",
    "        filled_data.append(data[i+1]) # Using next value\n",
    "      else:\n",
    "        filled_data.append(None) # if both previous and next value are None, keep it as None\n",
    "    else:\n",
    "      filled_data.append(value)\n",
    "  return filled_data\n",
    "\n",
    "print(nearest_neighbor_interpolate(list_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3], [4, 6], [7, 9]]\n"
     ]
    }
   ],
   "source": [
    "# Day 8: 2D List\n",
    "lst_data = []\n",
    "lst_sub_data = []\n",
    "\n",
    "# Create the 3x3 lst_data\n",
    "count = 1\n",
    "for i in range(3):\n",
    "    row = []\n",
    "    for j in range(3):\n",
    "        row.append(count)\n",
    "        count += 1\n",
    "    lst_data.append(row)\n",
    "\n",
    "# # Create lst_sub_data with values from index 0 and 2 of lst_data\n",
    "for row in lst_data:\n",
    "    lst_sub_data.append([row[0], row[2]])\n",
    "\n",
    "# Print lst_sub_data\n",
    "print(lst_sub_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 6, 9], [5, 8, 11], [8, 8, 10]]\n",
      "[[-1, -2, -3], [3, 2, 1], [6, 8, 8]]\n",
      "[[7, 10, 19], [19, 31, 55], [31, 52, 91]]\n"
     ]
    }
   ],
   "source": [
    "# Day 8: Matrix Presentation using List\n",
    "mat_A = [[1,2,3], [4,5,6], [7,8,9]]\n",
    "mat_B = [[2,4,6], [1,3,5], [1,0,1]]\n",
    "\n",
    "sum_matrix = [[0, 0, 0], [0, 0, 0], [0, 0, 0]]\n",
    "for i in range(len(mat_A)):\n",
    "  for j in range(len(mat_A[0])):\n",
    "    sum_matrix[i][j] = mat_A[i][j] + mat_B[i][j]\n",
    "print(sum_matrix)\n",
    "\n",
    "substract_mat = [[0, 0, 0], [0, 0, 0], [0, 0, 0]]\n",
    "for i in range(len(mat_A)):\n",
    "  for j in range(len(mat_A[0])):\n",
    "    substract_mat[i][j] = mat_A[i][j] - mat_B[i][j]\n",
    "print(substract_mat)\n",
    "\n",
    "def matrix_dot_product(mat_A, mat_B):\n",
    "  # Ensture matrix A and B are same number of columes\n",
    "  if len(mat_A[0]) != len(mat_B):\n",
    "    return None\n",
    "\n",
    "  result = [[0, 0, 0], [0, 0, 0], [0, 0, 0]]\n",
    "\n",
    "  # Iterate through rows of mat_A\n",
    "  for i in range(len(mat_A)):\n",
    "    # Iterate through columns of mat_B\n",
    "    for j in range(len(mat_B[0])):\n",
    "      # Iterate through rows of mat_B (columns of mat_A)\n",
    "      for k in range(len(mat_B)):\n",
    "        result[i][j] += mat_A[i][k] * mat_B[k][j]\n",
    "\n",
    "  return result\n",
    "\n",
    "result = matrix_dot_product(mat_A, mat_B)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AI', 'listen', 'music']\n"
     ]
    }
   ],
   "source": [
    "# Day 8: List comprehension\n",
    "stop_words = [\"I\",\"love\",\"and\",\"to\"]\n",
    "input = \"I love AI and listen to music\"\n",
    "\n",
    "result = [word for word in input.split() if word not in stop_words]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Max Scaling Normalizaton\n",
      "Test case 1: [0.0, 0.28, 0.52, 0.76, 1.0]\n",
      "Test case 2: [0.0, 0.25, 0.5, 0.75, 1.0]\n",
      "Test case 3: [0.0, 0.25, 0.5, 0.75, 1.0]\n",
      "Moving Average\n",
      "Test case 1: [2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0]\n",
      "Test case 2: [25.0, 35.0, 45.0, 55.0]\n",
      "Test case 3: [7.5, 12.5, 17.5, 22.5]\n",
      "Dot Product\n",
      "Test case 1: 32\n",
      "Test case 2: 44\n",
      "Test case 3: 14\n",
      "Test case 1: 1\n",
      "Test case 2: 1\n",
      "Test case 3: 0\n"
     ]
    }
   ],
   "source": [
    "# Day 8: Mathematics with List\n",
    "\n",
    "# Normalizaton - Min Max Scaling\n",
    "\n",
    "test_cases = [\n",
    "    [11, 18, 24, 30, 36],[50, 100, 150, 200, 250] ,[3, 5, 7, 9, 11]\n",
    "]\n",
    "\n",
    "def normalize(list_data):\n",
    "  result = []\n",
    "  for value in list_data:\n",
    "    result.append((value - min(list_data)) / (max(list_data) - min(list_data)))\n",
    "  return result\n",
    "\n",
    "\n",
    "print(\"Min Max Scaling Normalizaton\")\n",
    "for i, test in enumerate(test_cases):\n",
    "  result = normalize(test)\n",
    "  print(f\"Test case {i+1}: {result}\" )\n",
    "\n",
    "# Moving Average\n",
    "print(\"Moving Average\")\n",
    "\n",
    "test_cases = [([1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9] , 3) ,\n",
    "([10 , 20 , 30 , 40 , 50 , 60 , 70] , 4) ,\n",
    "([5 , 10 , 15 , 20 , 25] , 2)]\n",
    "\n",
    "def moving_average(list_data, k):\n",
    "  result = []\n",
    "  for i in range(len(list_data) - k + 1):\n",
    "    result.append(sum(list_data[i:i+k]) / k)\n",
    "  return result\n",
    "\n",
    "for i, (test, k) in enumerate(test_cases):\n",
    "  result = moving_average(test, k)\n",
    "  print(f\"Test case {i+1}: {result}\" )\n",
    "\n",
    "# Dot product\n",
    "print(\"Dot Product\")\n",
    "def dot_product(v1, v2):\n",
    "  result = 0\n",
    "  for i in range(len(v1)):\n",
    "    result += v1[i] * v2[i]\n",
    "  return result\n",
    "\n",
    "test_cases = [\n",
    "    ([1 , 2 , 3] , [4 , 5 , 6]) ,\n",
    "    ([2 , 4 , 6] , [1 , 3 , 5]) ,\n",
    "    ([0 , 1 , 2] , [3 , 4 , 5])\n",
    "]\n",
    "\n",
    "for i, (v1, v2) in enumerate(test_cases):\n",
    "  result = dot_product(v1, v2)\n",
    "  print(f\"Test case {i+1}: {result}\" )\n",
    "\n",
    "# Perceptron\n",
    "def perceptron_relu(weights, inputs, bias):\n",
    "  result = bias\n",
    "  for i in range(len(weights)):\n",
    "    result += weights[i] * inputs[i]\n",
    "  if result > 0:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "test_cases = [\n",
    "    ([0.5 , -0.6 , 0.8] , [1.0 , 0.0 , 1.0] , -0.3) ,\n",
    "    ([0.2 , 0.5 , -0.4] , [1.0 , 2.0 , -1.0] , 0.1) ,\n",
    "    ([1.0 , -1.0 , 0.5] , [0.5 , 1.0 , -0.5] , -0.2)\n",
    "]\n",
    "\n",
    "for i, (weights, inputs, bias) in enumerate(test_cases):\n",
    "  result = perceptron_relu(weights, inputs, bias)\n",
    "  print(f\"Test case {i+1}: {result}\" )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
